{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Tuning using Final Augmented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run helper functions script to load packages, data and functions\n",
    "%run -i helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in helper functions\n",
    "\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from math import sin, cos, pi\n",
    "\n",
    "def plot_img(image, label, axis):\n",
    "    image = image.reshape(96,96)\n",
    "    axis.imshow(image, cmap='gray')\n",
    "    axis.scatter(label[0::2], label[1::2], s=24, marker ='.', c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create training data scenarios based on options to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset with no missing values: (2140, 31)\n"
     ]
    }
   ],
   "source": [
    "# create 'partial' (missing values) dataset from train_data\n",
    "\n",
    "train_data_partial = train_data.dropna()\n",
    "print(\"Shape of training dataset with no missing values: {}\".format(train_data_partial.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training data with missing values:\n",
      "Training features shape: (7049, 96, 96, 1)\n",
      "Training labels shape: (7049, 30)\n",
      "Test features shape: (1783, 96, 96, 1)\n",
      "CPU times: user 14.9 s, sys: 1.79 s, total: 16.7 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# separate data into features and labels using helper functions\n",
    "\n",
    "X_full = get_features(train_data, dim=2)\n",
    "y_full = get_labels(train_data)\n",
    "X_test = get_features(test_data, dim=2)\n",
    "\n",
    "print(\"Full training data with missing values:\")\n",
    "print(\"Training features shape: {}\".format(X_full.shape))\n",
    "print(\"Training labels shape: {}\".format(y_full.shape))\n",
    "print(\"Test features shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial training data with NO missing values:\n",
      "Training features shape: (2140, 96, 96, 1)\n",
      "Training labels shape: (2140, 30)\n",
      "CPU times: user 2.53 s, sys: 91.2 ms, total: 2.62 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# drop rows with missing values\n",
    "# get features function didn't work after rows were dropped\n",
    "\n",
    "def load_images(image_data):\n",
    "    images = []\n",
    "    for idx, df in image_data.iterrows():\n",
    "        image = np.array(df['Image'].split(' '), dtype=int)\n",
    "        image = np.reshape(image, (96,96,1))\n",
    "        images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "X_partial = load_images(train_data_partial)\n",
    "\n",
    "y_partial = train_data_partial.drop(\"Image\", axis = 1).to_numpy()\n",
    "\n",
    "print(\"Partial training data with NO missing values:\")\n",
    "print(\"Training features shape: {}\".format(X_partial.shape))\n",
    "print(\"Training labels shape: {}\".format(y_partial.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pixels not yet normalized.  Need to divide by 255.\n",
    "# consider adding as a helper function\n",
    "\n",
    "def convert_images(image_data):\n",
    "    temp = np.array(image_data)/255\n",
    "    return temp\n",
    "\n",
    "X_full_converted = convert_images(X_full)\n",
    "X_partial_converted = convert_images(X_partial)\n",
    "X_test_converted = convert_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/W207/cnn/final_project_w207/helper_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full_converted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m210\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m210\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_img' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis = plt.subplots()\n",
    "plot_img(X_full_converted[210], y_full[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to flip images horizontally\n",
    "\n",
    "def flip_horizontal(features, labels):\n",
    "    flipped_labels = []\n",
    "    flipped_features = np.flip(features, axis=2)\n",
    "    for index, value in enumerate(labels):\n",
    "        flipped_labels.append([96.-coor if index%2==0 else coor for index, coor in enumerate(value)])\n",
    "    return flipped_features, np.asarray(flipped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = flip_horizontal(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example\n",
    "fig, axis = plt.subplots()\n",
    "plot_img(test_feat[210], test_lab[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_full_converted), X_full_converted.shape)\n",
    "print(type(X_partial_converted), X_partial_converted.shape)\n",
    "print(type(y_full), y_full.shape)\n",
    "print(type(y_partial), y_partial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat2, test_lab2 = flip_horizontal(X_partial_converted, y_partial)\n",
    "print(test_feat2.shape)\n",
    "print(test_lab2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example\n",
    "fig, axis = plt.subplots()\n",
    "plot_img(test_feat2[210], test_lab2[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to rotate images\n",
    "# https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n",
    "\n",
    "# arbitary list of angles to use to rotate the images\n",
    "angle_list = [5, 7.5, 10, 12.5, 15] \n",
    "\n",
    "def perform_rotation(features, labels):\n",
    "    rotated_labels = []\n",
    "    rotated_features = []\n",
    "    for item in angle_list:    \n",
    "        for angle in [item,-item]:\n",
    "            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n",
    "            angle_radians = -angle*pi/180. \n",
    "            \n",
    "            # features\n",
    "            for feat in features:\n",
    "                rotated_feat = cv2.warpAffine(feat, M, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                rotated_features.append(rotated_feat)\n",
    "            \n",
    "            # labels\n",
    "            for lab in labels:\n",
    "                rotated_lab = lab - 48.\n",
    "                for idx in range(0,len(rotated_lab),2):\n",
    "                    rotated_lab[idx] = rotated_lab[idx]*cos(angle_radians)-rotated_lab[idx+1]*sin(angle_radians)\n",
    "                    rotated_lab[idx+1] = rotated_lab[idx]*sin(angle_radians)+rotated_lab[idx+1]*cos(angle_radians)\n",
    "                rotated_lab += 48.   # Add the earlier subtracted value\n",
    "                rotated_labels.append(rotated_lab)\n",
    "            \n",
    "    return np.reshape(rotated_features,(-1,96,96,1)), np.asarray(rotated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = perform_rotation(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example\n",
    "fig, axis = plt.subplots()\n",
    "plot_img(test_feat[210], test_lab[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to update image lighting\n",
    "\n",
    "# arbitrary list of lighting factors to use to brighten/dim the images\n",
    "lighting_factor_list = [0.5, 0.75, 1.25, 1.5]\n",
    "\n",
    "def update_lighting(features, labels):\n",
    "    updated_features = []\n",
    "    updated_labels = []\n",
    "    for item in lighting_factor_list:\n",
    "        new_features = np.clip(features*item, 0.0, 1.0)\n",
    "        updated_features.extend(new_features)\n",
    "        updated_labels.extend(labels)\n",
    "    return np.asarray(updated_features), np.asarray(updated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = update_lighting(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to move the center of the image up, down, left and right\n",
    "\n",
    "# arbitrary list of pixel values to use to move center of image\n",
    "pixel_moves = [4, 8, 16, 32]\n",
    "\n",
    "def move_center(features, labels):\n",
    "    shifted_features = []\n",
    "    shifted_labels = []\n",
    "    for item in pixel_moves:\n",
    "        for (xval,yval) in [(item,item),(-item,item),(item,-item),(-item,-item)]:\n",
    "            M = np.float32([[1,0,xval],[0,1,yval]])\n",
    "            for feat, lab in zip(features, labels):\n",
    "                shifted_feature = cv2.warpAffine(feat, M, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                shifted_label = np.array([(point+xval) if idx%2==0 else (point+yval) for idx, point in enumerate(lab)])\n",
    "                if np.all(0.0<shifted_label) and np.all(shifted_label<96.0):\n",
    "                    shifted_features.append(shifted_feature.reshape(96,96,1))\n",
    "                    shifted_labels.append(shifted_label)\n",
    "    shifted_labels = np.clip(shifted_labels,0.0,96.0)\n",
    "    return np.asarray(shifted_features), shifted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = move_center(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to add noise to images\n",
    "\n",
    "# arbitrary noise factor\n",
    "noise_factor = 0.02\n",
    "\n",
    "def add_noise(features, labels):\n",
    "    noise_features = []\n",
    "    for feat in features:\n",
    "        noise_feat = cv2.add(feat, noise_factor*np.random.randn(96,96,1))\n",
    "        noise_features.append(noise_feat.reshape(96,96,1))\n",
    "    return np.asarray(noise_features), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = add_noise(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# build up training dataset using augmentation methods\n",
    "\n",
    "# for partial dataset\n",
    "\n",
    "# # control table used to apply augmentation methods; code currently assumes all are set to True\n",
    "# # ignore\n",
    "# flip = True\n",
    "# rotate = True\n",
    "# light = True\n",
    "# move = True\n",
    "# noise = True\n",
    "\n",
    "# progress through augmentations\n",
    "print(\"\\nPartial training data with NO missing values\\nBefore augmentation steps:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_converted.shape, y_partial.shape))\n",
    "\n",
    "# flip\n",
    "X_partial_flip, y_partial_flip = flip_horizontal(X_partial_converted, y_partial)\n",
    "X_partial_accum1 = np.concatenate((X_partial_converted, X_partial_flip))\n",
    "y_partial_accum1 = np.concatenate((y_partial, y_partial_flip))\n",
    "print(\"\\nAfter flipping horizontally:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum1.shape, y_partial_accum1.shape))\n",
    "\n",
    "# rotate\n",
    "X_partial_rotate, y_partial_rotate = perform_rotation(X_partial_converted, y_partial)\n",
    "X_partial_accum2 = np.concatenate((X_partial_accum1, X_partial_rotate))\n",
    "y_partial_accum2 = np.concatenate((y_partial_accum1, y_partial_rotate))\n",
    "print(\"\\nAfter performing rotations:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum2.shape, y_partial_accum2.shape))\n",
    "    \n",
    "# light\n",
    "X_partial_light, y_partial_light = update_lighting(X_partial_converted, y_partial)\n",
    "X_partial_accum3 = np.concatenate((X_partial_accum2, X_partial_light))\n",
    "y_partial_accum3 = np.concatenate((y_partial_accum2, y_partial_light))\n",
    "print(\"\\nAfter updating lighting:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum3.shape, y_partial_accum3.shape))\n",
    "    \n",
    "# move\n",
    "X_partial_move, y_partial_move = move_center(X_partial_converted, y_partial)\n",
    "X_partial_accum4 = np.concatenate((X_partial_accum3, X_partial_move))\n",
    "y_partial_accum4 = np.concatenate((y_partial_accum3, y_partial_move))\n",
    "print(\"\\nAfter moving the image center:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum4.shape, y_partial_accum4.shape))\n",
    "    \n",
    "# add noise\n",
    "X_partial_noise, y_partial_noise = add_noise(X_partial_converted, y_partial)\n",
    "X_partial_accum5 = np.concatenate((X_partial_accum4, X_partial_noise))\n",
    "y_partial_accum5 = np.concatenate((y_partial_accum4, y_partial_noise))\n",
    "print(\"\\nAfter adding noise:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum5.shape, y_partial_accum5.shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training a CNN on the Augmented Data, Evaluating on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Pull this into helper file\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_partial_accum5, y_partial_accum5, test_size=0.2, random_state=42)\n",
    "print(f\"Train examples: {X_train.shape[0]}\")\n",
    "print(f\"Train labels: {y_train.shape[0]}\")\n",
    "print(f\"Dev examples: {X_dev.shape[0]}\")\n",
    "print(f\"Dev labels {y_dev.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting example image dimensions\n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    "\n",
    "# ===Begin Specifying Baseline CNN Architecture===\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# 32 Convolution filters used\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Choose best features using max pooling layer \n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2))) #2d can be used for 2 dimensional input. No depth here.\n",
    "\n",
    "# 64 Convolution filters used, each of size 3x3\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Choose best features using max pooling layer \n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2))) #2d can be used for 2 dimensional input. No depth here.\n",
    "\n",
    "# Optional dropout layer. No need for baseline model.\n",
    "# cnn_model.add(Dropout(0.2)) #20% of the nodes are not going to activate at each layer of the network.\n",
    "\n",
    "# Flatten convolution features to pass through into the feed forward network. So 2d layer to 1d layer.\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(units=128, input_dim=128, activation='relu'))\n",
    "# 50 node network. Must be smaller than previous layer.\n",
    "# Input dimensions is 128 because \n",
    "\n",
    "# During gradient descent, you're refining 50 nod\n",
    "cnn_model.add(Dense(units=30, input_dim=50))  #10 node network\n",
    "\n",
    "# Summarize Model\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile and train the CNN\n",
    "cnn_model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "cnn_model.fit(X_train, y_train, epochs = 50, batch_size = 256, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model. This results in an error, but we might want to try to figure out how to store it.\n",
    "# import joblib\n",
    "# joblib.dump(cnn_model, \"baseline_model_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_y_dev_pred = cnn_model.predict(X_dev)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error #Eventually Add to helper file\n",
    "\n",
    "print('Baseline CNN Dev RMSE: %.2f'\n",
    "      % mean_squared_error(y_dev, cnn_y_dev_pred, squared=False))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
