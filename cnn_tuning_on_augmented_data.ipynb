{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Tuning using Final Augmented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run helper functions script to load packages, data and functions\n",
    "%run -i helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create training data scenarios based on options to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'partial' (missing values) dataset from train_data\n",
    "\n",
    "train_data_partial = train_data.dropna()\n",
    "print(\"Shape of training dataset with no missing values: {}\".format(train_data_partial.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# separate data into features and labels using helper functions\n",
    "\n",
    "X_full = get_features(train_data, dim=2)\n",
    "y_full = get_labels(train_data)\n",
    "X_test = get_features(test_data, dim=2)\n",
    "\n",
    "print(\"Full training data with missing values:\")\n",
    "print(\"Training features shape: {}\".format(X_full.shape))\n",
    "print(\"Training labels shape: {}\".format(y_full.shape))\n",
    "print(\"Test features shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# drop rows with missing values\n",
    "# get features function didn't work after rows were dropped\n",
    "\n",
    "def load_images(image_data):\n",
    "    images = []\n",
    "    for idx, df in image_data.iterrows():\n",
    "        image = np.array(df['Image'].split(' '), dtype=int)\n",
    "        image = np.reshape(image, (96,96,1))\n",
    "        images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "X_partial = load_images(train_data_partial)\n",
    "\n",
    "y_partial = train_data_partial.drop(\"Image\", axis = 1).to_numpy()\n",
    "\n",
    "print(\"Partial training data with NO missing values:\")\n",
    "print(\"Training features shape: {}\".format(X_partial.shape))\n",
    "print(\"Training labels shape: {}\".format(y_partial.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pixels not yet normalized.  Need to divide by 255.\n",
    "# consider adding as a helper function\n",
    "\n",
    "def convert_images(image_data):\n",
    "    temp = np.array(image_data)/255\n",
    "    return temp\n",
    "\n",
    "X_full_converted = convert_images(X_full)\n",
    "X_partial_converted = convert_images(X_partial)\n",
    "X_test_converted = convert_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots()\n",
    "plot_img(X_full_converted[210], y_full[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to flip images horizontally\n",
    "\n",
    "def flip_horizontal(features, labels):\n",
    "    flipped_labels = []\n",
    "    flipped_features = np.flip(features, axis=2)\n",
    "    for index, value in enumerate(labels):\n",
    "        flipped_labels.append([96.-coor if index%2==0 else coor for index, coor in enumerate(value)])\n",
    "    return flipped_features, np.asarray(flipped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = flip_horizontal(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example\n",
    "fig, axis = plt.subplots()\n",
    "plot_img(test_feat[210], test_lab[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_full_converted), X_full_converted.shape)\n",
    "print(type(X_partial_converted), X_partial_converted.shape)\n",
    "print(type(y_full), y_full.shape)\n",
    "print(type(y_partial), y_partial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat2, test_lab2 = flip_horizontal(X_partial_converted, y_partial)\n",
    "print(test_feat2.shape)\n",
    "print(test_lab2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example\n",
    "fig, axis = plt.subplots()\n",
    "plot_img(test_feat2[210], test_lab2[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to rotate images\n",
    "# https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n",
    "\n",
    "# arbitary list of angles to use to rotate the images\n",
    "angle_list = [5, 7.5, 10, 12.5, 15] \n",
    "\n",
    "def perform_rotation(features, labels):\n",
    "    rotated_labels = []\n",
    "    rotated_features = []\n",
    "    for item in angle_list:    \n",
    "        for angle in [item,-item]:\n",
    "            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n",
    "            angle_radians = -angle*pi/180. \n",
    "            \n",
    "            # features\n",
    "            for feat in features:\n",
    "                rotated_feat = cv2.warpAffine(feat, M, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                rotated_features.append(rotated_feat)\n",
    "            \n",
    "            # labels\n",
    "            for lab in labels:\n",
    "                rotated_lab = lab - 48.\n",
    "                for idx in range(0,len(rotated_lab),2):\n",
    "                    rotated_lab[idx] = rotated_lab[idx]*cos(angle_radians)-rotated_lab[idx+1]*sin(angle_radians)\n",
    "                    rotated_lab[idx+1] = rotated_lab[idx]*sin(angle_radians)+rotated_lab[idx+1]*cos(angle_radians)\n",
    "                rotated_lab += 48.   # Add the earlier subtracted value\n",
    "                rotated_labels.append(rotated_lab)\n",
    "            \n",
    "    return np.reshape(rotated_features,(-1,96,96,1)), np.asarray(rotated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = perform_rotation(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example\n",
    "fig, axis = plt.subplots()\n",
    "plot_img(test_feat[210], test_lab[210], axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to update image lighting\n",
    "\n",
    "# arbitrary list of lighting factors to use to brighten/dim the images\n",
    "lighting_factor_list = [0.5, 0.75, 1.25, 1.5]\n",
    "\n",
    "def update_lighting(features, labels):\n",
    "    updated_features = []\n",
    "    updated_labels = []\n",
    "    for item in lighting_factor_list:\n",
    "        new_features = np.clip(features*item, 0.0, 1.0)\n",
    "        updated_features.extend(new_features)\n",
    "        updated_labels.extend(labels)\n",
    "    return np.asarray(updated_features), np.asarray(updated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = update_lighting(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to move the center of the image up, down, left and right\n",
    "\n",
    "# arbitrary list of pixel values to use to move center of image\n",
    "pixel_moves = [4, 8, 16, 32]\n",
    "\n",
    "def move_center(features, labels):\n",
    "    shifted_features = []\n",
    "    shifted_labels = []\n",
    "    for item in pixel_moves:\n",
    "        for (xval,yval) in [(item,item),(-item,item),(item,-item),(-item,-item)]:\n",
    "            M = np.float32([[1,0,xval],[0,1,yval]])\n",
    "            for feat, lab in zip(features, labels):\n",
    "                shifted_feature = cv2.warpAffine(feat, M, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                shifted_label = np.array([(point+xval) if idx%2==0 else (point+yval) for idx, point in enumerate(lab)])\n",
    "                if np.all(0.0<shifted_label) and np.all(shifted_label<96.0):\n",
    "                    shifted_features.append(shifted_feature.reshape(96,96,1))\n",
    "                    shifted_labels.append(shifted_label)\n",
    "    shifted_labels = np.clip(shifted_labels,0.0,96.0)\n",
    "    return np.asarray(shifted_features), shifted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = move_center(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to add noise to images\n",
    "\n",
    "# arbitrary noise factor\n",
    "noise_factor = 0.02\n",
    "\n",
    "def add_noise(features, labels):\n",
    "    noise_features = []\n",
    "    for feat in features:\n",
    "        noise_feat = cv2.add(feat, noise_factor*np.random.randn(96,96,1))\n",
    "        noise_features.append(noise_feat.reshape(96,96,1))\n",
    "    return np.asarray(noise_features), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_feat, test_lab = add_noise(X_full_converted, y_full)\n",
    "print(test_feat.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# build up training dataset using augmentation methods\n",
    "\n",
    "# for partial dataset\n",
    "\n",
    "# # control table used to apply augmentation methods; code currently assumes all are set to True\n",
    "# # ignore\n",
    "# flip = True\n",
    "# rotate = True\n",
    "# light = True\n",
    "# move = True\n",
    "# noise = True\n",
    "\n",
    "# progress through augmentations\n",
    "print(\"\\nPartial training data with NO missing values\\nBefore augmentation steps:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_converted.shape, y_partial.shape))\n",
    "\n",
    "# flip\n",
    "X_partial_flip, y_partial_flip = flip_horizontal(X_partial_converted, y_partial)\n",
    "X_partial_accum1 = np.concatenate((X_partial_converted, X_partial_flip))\n",
    "y_partial_accum1 = np.concatenate((y_partial, y_partial_flip))\n",
    "print(\"\\nAfter flipping horizontally:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum1.shape, y_partial_accum1.shape))\n",
    "\n",
    "# rotate\n",
    "X_partial_rotate, y_partial_rotate = perform_rotation(X_partial_converted, y_partial)\n",
    "X_partial_accum2 = np.concatenate((X_partial_accum1, X_partial_rotate))\n",
    "y_partial_accum2 = np.concatenate((y_partial_accum1, y_partial_rotate))\n",
    "print(\"\\nAfter performing rotations:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum2.shape, y_partial_accum2.shape))\n",
    "    \n",
    "# light\n",
    "X_partial_light, y_partial_light = update_lighting(X_partial_converted, y_partial)\n",
    "X_partial_accum3 = np.concatenate((X_partial_accum2, X_partial_light))\n",
    "y_partial_accum3 = np.concatenate((y_partial_accum2, y_partial_light))\n",
    "print(\"\\nAfter updating lighting:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum3.shape, y_partial_accum3.shape))\n",
    "    \n",
    "# move\n",
    "X_partial_move, y_partial_move = move_center(X_partial_converted, y_partial)\n",
    "X_partial_accum4 = np.concatenate((X_partial_accum3, X_partial_move))\n",
    "y_partial_accum4 = np.concatenate((y_partial_accum3, y_partial_move))\n",
    "print(\"\\nAfter moving the image center:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum4.shape, y_partial_accum4.shape))\n",
    "    \n",
    "# add noise\n",
    "X_partial_noise, y_partial_noise = add_noise(X_partial_converted, y_partial)\n",
    "X_partial_accum5 = np.concatenate((X_partial_accum4, X_partial_noise))\n",
    "y_partial_accum5 = np.concatenate((y_partial_accum4, y_partial_noise))\n",
    "print(\"\\nAfter adding noise:\\nFeatures shape: {}     Labels shape: {}\".format(X_partial_accum5.shape, y_partial_accum5.shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training a CNN on the Augmented Data, Evaluating on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Pull this into helper file\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_partial_accum5, y_partial_accum5, test_size=0.2, random_state=42)\n",
    "print(f\"Train examples: {X_train.shape[0]}\")\n",
    "print(f\"Train labels: {y_train.shape[0]}\")\n",
    "print(f\"Dev examples: {X_dev.shape[0]}\")\n",
    "print(f\"Dev labels {y_dev.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting example image dimensions\n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    "\n",
    "# ===Begin Specifying Baseline CNN Architecture===\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# 32 Convolution filters used\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Choose best features using max pooling layer \n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2))) #2d can be used for 2 dimensional input. No depth here.\n",
    "\n",
    "# 64 Convolution filters used, each of size 3x3\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Choose best features using max pooling layer \n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2))) #2d can be used for 2 dimensional input. No depth here.\n",
    "\n",
    "# Optional dropout layer. No need for baseline model.\n",
    "# cnn_model.add(Dropout(0.2)) #20% of the nodes are not going to activate at each layer of the network.\n",
    "\n",
    "# Flatten convolution features to pass through into the feed forward network. So 2d layer to 1d layer.\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(units=128, input_dim=128, activation='relu'))\n",
    "# 50 node network. Must be smaller than previous layer.\n",
    "# Input dimensions is 128 because \n",
    "\n",
    "# During gradient descent, you're refining 50 nod\n",
    "cnn_model.add(Dense(units=30, input_dim=50))  #10 node network\n",
    "\n",
    "# Summarize Model\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile and train the CNN\n",
    "cnn_model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "cnn_model.fit(X_train, y_train, epochs = 50, batch_size = 256, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model. This results in an error, but we might want to try to figure out how to store it.\n",
    "# import joblib\n",
    "# joblib.dump(cnn_model, \"baseline_model_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_y_dev_pred = cnn_model.predict(X_dev)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error #Eventually Add to helper file\n",
    "\n",
    "print('Baseline CNN Dev RMSE: %.2f'\n",
    "      % mean_squared_error(y_dev, cnn_y_dev_pred, squared=False))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
